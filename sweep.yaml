# Sweep configuration for running many experiments
# Edit the grid values and fixed defaults as needed.

script: train.py           # Path to training script
data: train.csv.gz         # Dataset path
outdir_root: results       # Where all run folders live
name_template: "w{window}-ep{epochs}-lr{lr}-h{nhead}-L{layers}-ff{ff}-dm{d_model}-b{batch}"

# Parameters that are the same for every run
fixed:
  use_levels: 4
  batch: 512
  d_model: 128
  val_frac: 0.2

# Cartesian product grid to sweep over
grid:
  window: [2, 5, 10]
  epochs: [1, 2, 4, 8]
  lr: [0.0002, 0.0004, 0.0008]
  nhead: [4]
  layers: [2, 4]
  ff: [256, 512]

# Launcher options
launch:
  max_parallel: 2     # Increase for more concurrency
  dry_run: false      # true = only print commands, don't launch
  limit: null         # e.g., 10 to run only first 10 combos
